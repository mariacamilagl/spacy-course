---
type: slides
---

# Word vectors y similitud sem√°ntica

Notes: En esta lecci√≥n vas a aprender a usar spaCy para predecir qu√© tan
similares son documentos, spans o tokens entre s√≠.

Tambi√©n aprender√°s c√≥mo usar
<abbr title="Los word vectors son palabras o frases vinculadas a vectores de n√∫meros reales mediante diferentes m√©todos. En espa√±ol tambi√©n se conocen como vectores de palabras.">word
vectors</abbr> y c√≥mo aprovecharlos en tu aplicaci√≥n de NLP.

---

# Prediciendo similitud sem√°ntica

- `spaCy` puede comparar dos objetos y predecir similitud
- `Doc.similarity()`, `Span.similarity()` y `Token.similarity()`
- Toma otro objeto y devuelve un puntaje de similitud (del `0` al `1`)
- **Importante:** necesita el modelo que tiene los word vectors incluidos, por
  ejemplo:
  - ‚úÖ `en_core_web_md` (modelo mediano)
  - ‚úÖ `es_core_news_md` (modelo mediano espa√±ol)
  - ‚úÖ `en_core_web_lg` (modelo grande)
  - üö´ **NO** `en_core_web_sm` o `es_core_news_sm`(modelos peque√±os)

Notes: spaCy puede comparar dos objetos y predecir qu√© tan similares son - por
ejemplo, documentos, spans o tokens.

Los objetos `Doc`, `Token` y `Span` tienen un m√©todo `.similarity` que recibe
otro objeto y devuelve un n√∫mero de punto flotante entre 0 y 1 indicando qu√©
tan similares son.

Algo muy importante: Para poder usar similitud necesitas un modelo
m√°s grande de spaCy que incluya los word vectors.

Por ejemplo, el modelo de ingl√©s mediano o grande - pero _no_ el peque√±o. As√≠
que si quieres usar los vectores usa uno de los modelos que terminan en "md" o
"lg". Puedes ver m√°s detalles sobre esto en la
[documentaci√≥n de los modelos](https://spacy.io/models).

---

# Ejemplos de similitud (1)

```python
# Carga uno de los modelos m√°s grandes que contiene vectores
nlp = spacy.load("es_core_news_md")

# Compara dos documentos
doc1 = nlp("Me gusta la comida r√°pida")
doc2 = nlp("Me gusta la pizza")
print(doc1.similarity(doc2))
```

```out
0.9771402664001864
```

```python
# Compara dos tokens
doc = nlp("Me gusta la pizza y la pasta")
token1 = doc[3]
token2 = doc[6]
print(token1.similarity(token2))
```

```out
0.7795312
```

Notes: Aqu√≠ tenemos un ejemplo. Digamos que queremos determinar si dos
documentos son similares.

Primero, cargamos el modelo de espa√±ol mediano "es_core_news_md".

Despu√©s podemos crear dos objetos doc y usar el m√©todo `similarity` del primer
doc para compararlo con el segundo.

Aqu√≠ tenemos un puntaje de similitud alto de 0.97 para "Me gusta la comida r√°pida" y "Me gusta la pizza".

Lo mismo funciona para los tokens.

De acuerdo con los word vectors, los tokens "pizza" y "pasta" son medianamente
parecidos y reciben un puntaje de 0.78.

---

# Ejemplos de similitud (2)

```python
# Compara un documento con un token
doc = nlp("Me gusta la pizza")
token = nlp("jab√≥n")[0]

print(doc.similarity(token))
```

```out
0.4755507088511145
```

```python
# Compara un span con un documento
span = nlp("Me gusta la pizza y la pasta")[2:7]
doc = nlp("McDonalds vende hamburguesas")

print(span.similarity(doc))
```

```out
0.6243837841459509
```

Notes: Tambi√©n puedes usar los m√©todos `similarity` para comparar diferentes
tipos de objetos.

Por ejemplo, un documento y un token.

Aqu√≠ el puntaje de similitud es bastante bajo y los dos objetos se consideran
bastante diferentes.

Aqu√≠ tenemos otro ejemplo que compara un span - "la pizza y la pasta" ‚Äì a un
documento sobre McDonalds.

El puntaje que obtuvimos aqu√≠ es de 0.62, as√≠ que determinamos que son
medianamente similares.

---

# ¬øC√≥mo predice spaCy la similitud?

- La similitud se determina usando **word vectors**
- Representaciones multidimensionales de significados de palabras
- Generado usando un algoritmo como
  [Word2Vec](https://en.wikipedia.org/wiki/Word2vec) y mucho texto
- Puede a√±adirse a los modelos estad√≠sticos de spaCy
- Por defecto: similitud coseno, pero puede cambiarse por otra medida de semejanza
- Los vectores de los `Doc` y `Span` tienen por defecto el valor del promedio
  de los vectores de los tokens
- Las frases cortas son mejores que los documentos largos con muchas palabras
  irrelevantes

Notes: ¬øPero c√≥mo hace esto spaCy detr√°s de c√°maras?

La similitud se determina usando word vectors, que son representaciones
multidimensionales de los significados de las palabras.

Puedes que hayas escuchado sobre Word2Vec, que es un algoritmo que se usa
frecuentemente para entrenar vectores de palabras desde texto puro.

Los vectores se pueden a√±adir a los modelos estad√≠sticos de spaCy.

Por defecto, la similitud que devuelve spaCy es una similitud coseno entre dos
vectores, pero esto puede cambiarse si es necesario.

Los vectores para objetos que consisten de varios tokens, como el Doc y el Span
tienen por defecto el valor promedio de los vectores de sus tokens.

Es por esto que normalmente puedes obtener m√°s valor con las frases m√°s cortas, ya que contienen menos palabras irrelevantes.

---

# Word vectors en spaCy

```python
# Carga uno de los modelos m√°s grandes que contiene vectores
nlp = spacy.load("es_core_news_md")

doc = nlp("Tengo una manzana")
# Accede al vector a trav√©s del atributo token.vector
print(doc[2].vector)
```

```out
[-0.162944,   0.042666,   0.405069,
 -0.884944,   0.13951 ,   1.37826 ,
 -0.807906,  -0.432592,  -0.747897,  
  0.953742,   0.90389 ,  -0.514217,
  0.360039,  -0.409261,   1.11574 ,
 -0.407411,   0.118361,  -0.426352,
 -0.315689,   0.027726,   0.79418 ,
 -0.99135 ,   0.147428,   0.36956 ,
  0.547555,  -0.023946,  -2.024585,
 -0.122916,   0.406145,   0.911639,
 ...
```

Notes: Aqu√≠ hay un ejemplo para darte una idea de c√≥mo se ven estos vectores.

Primero, cargamos el modelo mediano otra vez. Este contiene word vectors.

Despu√©s, podemos procesar un texto y buscar el vector de un token usando el
atributo `.vector`.

El resultado es un vector con 300 dimensiones de la palabra "manzana".

---

# La similitud depende del contexto de la aplicaci√≥n

- √ötil para muchas aplicaciones: sistemas de recomendaciones, reporte
  de duplicados, etc.
- No hay una definici√≥n objetiva de "similitud"
- Depende del contexto y de lo que la aplicaci√≥n necesita hacer

```python
doc1 = nlp("Me gustan los gatos")
doc2 = nlp("Odio a los gatos")

print(doc1.similarity(doc2))
```

```out
0.9073441516522552
```

Notes: Predecir similitud puede ser muy √∫til para muchos tipos de aplicaciones.
Por ejemplo, para recomendarle al usuario textos parecidos basados en los que ya
ha le√≠do. Tambi√©n puede ser √∫til para reportar contenido duplicado, como posts
en una plataforma en l√≠nea.

Sin embargo, es importante tener presente que no hay una definici√≥n objetiva de
lo que es similar y lo que no. Siempre depende del contexto y de lo que tu
aplicaci√≥n tiene que hacer.

Aqu√≠ tenemos un ejemplo: los word vectors por defecto de spaCy le asignan un
puntaje de similitud muy alto a "Me gustan los gatos" y "Odio a los gatos". Esto tiene
sentido porque ambas frases expresan un sentimiento sobre los gatos. Pero en
otro contexto de aplicaci√≥n estas frases pueden ser consideradas muy
_diferentes_, porque hablan sobre el sentimiento opuesto.

---

# ¬°Practiquemos!

Notes: Ahora es tu turno. Probemos algunos de los word vectors de spaCy y
us√©moslos para predecir similitudes.
